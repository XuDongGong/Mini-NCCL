#pragma once

#include "mini_nccl_api.h"
#include <cuda_runtime.h>
#include <vector>
#include <memory>
#include <string>
#include <stdexcept>
#include <cstdint>

// å‘Šè¯‰ç¼–è¯‘å™¨æŸæ¡åˆ†æ”¯å‘ç”Ÿçš„æ¦‚ç‡æä½ (unlikely) æˆ–æé«˜ (likely)
#if defined(__GNUC__) || defined(__clang__)
    #define likely(x)       __builtin_expect(!!(x), 1)
    #define unlikely(x)     __builtin_expect(!!(x), 0)
#else
    #define likely(x)       (x)
    #define unlikely(x)     (x)
#endif

namespace mini_nccl {

// å®šä¹‰å†…éƒ¨ä½¿ç”¨çš„æšä¸¾
enum class DataType {
    Float32 = 0,
    Float64 = 1,
    Int32   = 2
};

enum class RedOp {
    Sum = 0,
    Prod = 1,
    Max = 2,
    Min = 3
};

class MemoryRegion {
public:
    virtual ~MemoryRegion() = default;
    virtual void* ptr() const = 0;
    virtual size_t size() const = 0;
    virtual uint32_t rkey() const = 0;
};

class Request {
public:
    virtual ~Request() = default;
    virtual void wait() = 0;
    virtual bool isCompleted() const = 0;
    virtual void release() = 0;
};

class Transport {
public:
    virtual ~Transport() = default;
    virtual void init() = 0;
    
    virtual Request* isend(int rank, std::shared_ptr<MemoryRegion> mr, size_t offset, size_t length) = 0;
    virtual Request* irecv(int rank, std::shared_ptr<MemoryRegion> mr, size_t offset, size_t length) = 0;
    virtual std::shared_ptr<MemoryRegion> registerMemory(void* ptr, size_t size) = 0;

    virtual uint32_t* get_flags_ptr() = 0;
    virtual uint32_t* get_abort_flag_dev_ptr() = 0;
    virtual void abort() = 0;

    virtual Request* write(int rank, std::shared_ptr<MemoryRegion> local_mr, size_t offset, size_t length,
                           uint64_t remote_addr, uint32_t remote_rkey, bool signaled = true) = 0;

    virtual Request* write_signal(int rank, int flag_idx, uint32_t value, bool signaled = true) = 0;
    
    // æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†ä¿æŒ API ç®€å•ï¼Œæˆ‘ä»¬æš‚æ—¶ä¸åœ¨åŸºç±»å±•å¼€ DynamicInfo çš„å‚æ•°
    // å®é™…è°ƒç”¨æ—¶ä¼šä½¿ç”¨ dynamic_pointer_cast<RDMATransport>
};

class Context {
public:
    // ä¿®æ”¹: æ„é€ å‡½æ•°æ”¹ä¸ºå£°æ˜ï¼Œå®ç°åœ¨ .cu æ–‡ä»¶ä¸­
    Context(int rank, int size, std::shared_ptr<Transport> transport);
    
    ~Context() {
        if (host_buffer_) cudaFreeHost(host_buffer_);
    }

    int rank() const { return rank_; }
    int size() const { return size_; }
    std::shared_ptr<Transport> transport() const { return transport_; }
    
    std::shared_ptr<MemoryRegion> registerMemory(void* ptr, size_t size) {
        return transport_->registerMemory(ptr, size);
    }

    // >>> ğŸš€ æå‡äº”: å†…å­˜å¤ç”¨æœºåˆ¶æ¥å£ >>>
    void* get_scratch_buffer(int idx) {
        // ç®€å•çš„åŒç¼“å†²ç´¢å¼•æ£€æŸ¥
        if (idx < 0 || idx > 1) return nullptr;
        if (!host_buffer_) return nullptr;
        return (char*)host_buffer_ + idx * max_slice_size_;
    }

    void allocate_scratch_buffer(size_t slice_size) {
        if (host_buffer_) return; 
        max_slice_size_ = slice_size; 
        // å…³é”®ç‚¹: ä½¿ç”¨ cudaHostAllocMapped 
        // 1. å…è®¸ GPU Kernel ç›´æ¥è®¿é—® (Zero-Copy)
        // 2. é¿å… "invalid argument" æˆ– Sticky Error
        cudaError_t err = cudaHostAlloc(&host_buffer_, max_slice_size_ * 2, cudaHostAllocMapped);
        if (err != cudaSuccess) {
            throw std::runtime_error("Failed to allocate context scratch buffer: " + std::string(cudaGetErrorString(err)));
        }
    }
    // <<< æå‡äº”ç»“æŸ <<<

private:
    int rank_;
    int size_;
    std::shared_ptr<Transport> transport_;
    
    // å†…å­˜æ± å˜é‡
    void* host_buffer_ = nullptr;
    size_t max_slice_size_ = 0;
};

void allreduce(void* data, int count, DataType dtype, RedOp op, std::shared_ptr<Context> ctx, cudaStream_t stream);

} // namespace mini_nccl